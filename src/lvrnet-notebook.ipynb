{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achleschwar/anaconda3/envs/pointnet/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import time,math\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch,warnings\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.transforms import functional as FF\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision.models import vgg16\n",
    "from model import *\n",
    "from losses import *\n",
    "from PerceptualLoss import PerLoss\n",
    "from metrics import psnr,ssim\n",
    "from torch.backends import cudnn\n",
    "from torch import optim\n",
    "from dataset import AFO_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule_cosdecay(t,T,init_lr=1e-4):\n",
    "    lr=0.5*(1+math.cos(t*math.pi/T))*init_lr\n",
    "    return lr\n",
    "\n",
    "def train(net,train_loader,test_loader,optim,criterion, epochs):\n",
    "    losses=[]\n",
    "    start_step=0\n",
    "    T=epochs\n",
    "    max_ssim=0\n",
    "    max_psnr=0\n",
    "    ssims=[]\n",
    "    psnrs=[]\n",
    "    if resume:\n",
    "        print(f'resume from {model_dir}')\n",
    "        ckp=torch.load(model_dir)\n",
    "        losses=ckp['losses']\n",
    "        net.load_state_dict(ckp['model'])\n",
    "        start_step=ckp['step']\n",
    "        max_ssim=ckp['max_ssim']\n",
    "        max_psnr=ckp['max_psnr']\n",
    "        psnrs=ckp['psnrs']\n",
    "        ssims=ckp['ssims']\n",
    "        print(f'start_step:{start_step} start training ---')\n",
    "    else :\n",
    "        print('train from scratch *** ')\n",
    "    start_time=time.time()    \n",
    "    for step in range(start_step+1,T+1):\n",
    "        for x, y, _ in tqdm(train_loader):\n",
    "            net.train()\n",
    "            lr=1e-4\n",
    "            lr=lr_schedule_cosdecay(step,T)\n",
    "            for param_group in optim.param_groups:\n",
    "                param_group[\"lr\"] = lr  \n",
    "                \n",
    "            x=x.to(device);y=y.to(device)\n",
    "            out=net(x)\n",
    "            loss=criterion[0](out,y)\n",
    "            if perloss:\n",
    "                loss2=criterion[1](out,y)\n",
    "                loss=loss+0.04*loss2\n",
    "            if edgeloss:\n",
    "                loss3 = criterion[2](out, y)\n",
    "                loss = loss+loss3\n",
    "            if fftloss:\n",
    "                loss4 = criterion[3](out, y)\n",
    "                loss = loss + 0.01*loss4\n",
    "\n",
    "    \n",
    "            loss.backward()\n",
    "\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "        print(f'\\rtrain loss : {loss.item():.5f}| step :{step}/{T}|lr :{lr :.7f} |time_used :{(time.time()-start_time)/60 :.1f}',end='',flush=True)\n",
    "\n",
    "#         #with SummaryWriter(logdir=log_dir,comment=log_dir) as writer:\n",
    "#         #\twriter.add_scalar('data/loss',loss,step)\n",
    "\n",
    "        if step % 1 ==0 :\n",
    "            with torch.no_grad():\n",
    "                ssim_eval,psnr_eval=test(net,test_loader, max_psnr,max_ssim,step)\n",
    "\n",
    "            print(f'\\nstep :{step} |ssim:{ssim_eval:.4f}| psnr:{psnr_eval:.4f}')\n",
    "\n",
    "            # with SummaryWriter(logdir=log_dir,comment=log_dir) as writer:\n",
    "            # \twriter.add_scalar('data/ssim',ssim_eval,step)\n",
    "            # \twriter.add_scalar('data/psnr',psnr_eval,step)\n",
    "            # \twriter.add_scalars('group',{\n",
    "            # \t\t'ssim':ssim_eval,\n",
    "            # \t\t'psnr':psnr_eval,\n",
    "            # \t\t'loss':loss\n",
    "            # \t},step)\n",
    "            ssims.append(ssim_eval)\n",
    "            psnrs.append(psnr_eval)\n",
    "            if psnr_eval > max_psnr :\n",
    "                max_ssim=max(max_ssim,ssim_eval)\n",
    "                max_psnr=max(max_psnr,psnr_eval)\n",
    "                torch.save({\n",
    "                            'step':step,\n",
    "                            'max_psnr':max_psnr,\n",
    "                            'max_ssim':max_ssim,\n",
    "                            'ssims':ssims,\n",
    "                            'psnrs':psnrs,\n",
    "                            'losses':losses,\n",
    "                            'model':net.state_dict()\n",
    "                },f'/home/achleshwarl/AFO/NAF-FFA/weights/LPEF_3_10_Epoch{step}.pth')\n",
    "                print(f'\\n model saved at step :{step}| max_psnr:{max_psnr:.4f}|max_ssim:{max_ssim:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net,test_loader,max_psnr,max_ssim,step):\n",
    "\tnet.eval()\n",
    "\ttorch.cuda.empty_cache()\n",
    "\tssims=[]\n",
    "\tpsnrs=[]\n",
    "\t#s=True\n",
    "\tfor i ,(inputs,targets, _) in enumerate(test_loader):\n",
    "\t\tinputs=inputs.to(device);targets=targets.to(device)\n",
    "\t\tpred=net(inputs)\n",
    "\t\t# # print(pred)\n",
    "\t\t# tfs.ToPILImage()(torch.squeeze(targets.cpu())).save('111.png')\n",
    "\t\t# vutils.save_image(targets.cpu(),'target.png')\n",
    "\t\t# vutils.save_image(pred.cpu(),'pred.png')\n",
    "\t\tssim1=ssim(pred,targets).item()\n",
    "\t\tpsnr1=psnr(pred,targets)\n",
    "\t\tssims.append(ssim1)\n",
    "\t\tpsnrs.append(psnr1)\n",
    "\t\t#if (psnr1>max_psnr or ssim1 > max_ssim) and s :\n",
    "\t\t#\t\tts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])\n",
    "\t\t#\t\tvutils.save_image(ts,f'samples/{model_name}/{step}_{psnr1:.4}_{ssim1:.4}.png')\n",
    "\t\t#\t\ts=False\n",
    "\treturn np.mean(ssims) ,np.mean(psnrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop size 200\n",
      "crop size 200\n"
     ]
    }
   ],
   "source": [
    "path='/home/achleschwar/lvrnet/data/train'#path to your 'data' folder\n",
    "train_data = AFO_Dataset(path,train=True, size=200) # size here refers to the crop_size\n",
    "train_loader=DataLoader(train_data,batch_size=1,shuffle=True)\n",
    "\n",
    "path='/home/achleschwar/lvrnet/data/test'#path to your 'data' folder\n",
    "test_data = AFO_Dataset(path,train=False, size=200)\n",
    "test_loader=DataLoader(test_data,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train from scratch *** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2913/2913 [24:33<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss : 0.56171| step :1/1|lr :0.0000000 |time_used :24.6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step :1 |ssim:0.5042| psnr:11.4133\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /home/achleshwarl/AFO/NAF-FFA/weights does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     39\u001b[0m resume\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m train(net,train_loader,test_loader,optimizer,criterion, epochs)\n",
      "Cell \u001b[0;32mIn[2], line 78\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, optim, criterion, epochs)\u001b[0m\n\u001b[1;32m     76\u001b[0m max_ssim\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(max_ssim,ssim_eval)\n\u001b[1;32m     77\u001b[0m max_psnr\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(max_psnr,psnr_eval)\n\u001b[0;32m---> 78\u001b[0m torch\u001b[39m.\u001b[39;49msave({\n\u001b[1;32m     79\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mstep\u001b[39;49m\u001b[39m'\u001b[39;49m:step,\n\u001b[1;32m     80\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mmax_psnr\u001b[39;49m\u001b[39m'\u001b[39;49m:max_psnr,\n\u001b[1;32m     81\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mmax_ssim\u001b[39;49m\u001b[39m'\u001b[39;49m:max_ssim,\n\u001b[1;32m     82\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mssims\u001b[39;49m\u001b[39m'\u001b[39;49m:ssims,\n\u001b[1;32m     83\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mpsnrs\u001b[39;49m\u001b[39m'\u001b[39;49m:psnrs,\n\u001b[1;32m     84\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mlosses\u001b[39;49m\u001b[39m'\u001b[39;49m:losses,\n\u001b[1;32m     85\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m:net\u001b[39m.\u001b[39;49mstate_dict()\n\u001b[1;32m     86\u001b[0m },\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/home/achleshwarl/AFO/NAF-FFA/weights/LPEF_3_10_Epoch\u001b[39;49m\u001b[39m{\u001b[39;49;00mstep\u001b[39m}\u001b[39;49;00m\u001b[39m.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     87\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m model saved at step :\u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m| max_psnr:\u001b[39m\u001b[39m{\u001b[39;00mmax_psnr\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m|max_ssim:\u001b[39m\u001b[39m{\u001b[39;00mmax_ssim\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pointnet/lib/python3.10/site-packages/torch/serialization.py:422\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    419\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 422\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    424\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pointnet/lib/python3.10/site-packages/torch/serialization.py:309\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m~/anaconda3/envs/pointnet/lib/python3.10/site-packages/torch/serialization.py:287\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_writer_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mstr\u001b[39;49m(name)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /home/achleshwarl/AFO/NAF-FFA/weights does not exist."
     ]
    }
   ],
   "source": [
    "#################\n",
    "## Train Model###\n",
    "#################\n",
    "models_={\n",
    "    'ffa':FFA(gps=3,blocks=16),\n",
    "}\n",
    "loaders_={\n",
    "    'train':train_loader,\n",
    "    'test':test_loader\n",
    "}\n",
    "\n",
    "net=models_['ffa']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net=net.to(device)\n",
    "if device=='cuda':\n",
    "    net=torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark=True\n",
    "\n",
    "perloss = True\n",
    "edgeloss = True\n",
    "fftloss = True\n",
    "criterion = []\n",
    "criterion.append(nn.L1Loss().to(device))\n",
    "if perloss:\n",
    "    vgg_model = vgg16(pretrained=True).features[:16]\n",
    "    vgg_model = vgg_model.to(device)\n",
    "    for param in vgg_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    criterion.append(PerLoss(vgg_model).to(device))\n",
    "if edgeloss:\n",
    "    criterion.append(EdgeLoss())\n",
    "if fftloss:\n",
    "    criterion.append(fftLoss())\n",
    "\n",
    "optimizer = optim.Adam(params=filter(lambda x: x.requires_grad, net.parameters()),lr=1e-4, betas = (0.9, 0.999), eps=1e-08)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "epochs = 1\n",
    "resume=False\n",
    "train(net,train_loader,test_loader,optimizer,criterion, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "943abed8b548dc55529bf4b37e8051f56393a56ce21c72ac2492697c518cf71c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

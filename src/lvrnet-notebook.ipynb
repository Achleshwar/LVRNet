{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys, math, time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch,warnings\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.transforms import functional as FF\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision.models import vgg16\n",
    "from model import *\n",
    "from losses import *\n",
    "from PerceptualLoss import PerLoss\n",
    "from metrics import psnr,ssim\n",
    "from torch.backends import cudnn\n",
    "from torch import optim\n",
    "from dataset import AFO_Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define model\n",
    "\n",
    "models_={\n",
    "    'lvrnet':LVRNet(gps=3,blocks=16),\n",
    "}\n",
    "\n",
    "net=models_['lvrnet']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net=net.to(device)\n",
    "\n",
    "if device=='cuda':\n",
    "    net=torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wts = \"../weights/LPEF_Epoch47.pth\"\n",
    "\n",
    "ckp=torch.load(model_wts)\n",
    "net.load_state_dict(ckp['model'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "demo_dir = \"../demo\"\n",
    "\n",
    "## go in demo_dir and get images\n",
    "img_paths = glob(os.path.join(demo_dir, \"*.jpg\"))\n",
    "n_imgs = len(img_paths)\n",
    "\n",
    "## load images\n",
    "inputs = []\n",
    "for img_path in img_paths:\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize((456, 256))\n",
    "    # img = img.resize((img.size[0] // 2, img.size[1] // 2)) # this might give OOM error\n",
    "    img = tfs.ToTensor()(img)\n",
    "    inputs.append(img)\n",
    "\n",
    "inputs = torch.stack(inputs, dim=0).to(device) # (#images, 3, 456, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "torch.cuda.empty_cache()\n",
    "for i in range(n_imgs):\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        pred=net(inputs[i].unsqueeze(0))\n",
    "    end = time.time()\n",
    "    print(\"Time taken for inference: \", end-start)\n",
    "    \n",
    "    # visualize outputs\n",
    "    merged_io = torch.cat([inputs[i].unsqueeze(0),pred],dim=0)\n",
    "    grid_img = vutils.make_grid(merged_io, nrow=2, normalize=True, scale_each=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(grid_img.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "943abed8b548dc55529bf4b37e8051f56393a56ce21c72ac2492697c518cf71c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
